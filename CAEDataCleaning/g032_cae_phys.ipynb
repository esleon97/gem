{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader,TensorDataset\n",
    "from pytorch_model_summary import summary\n",
    "from tsnecuda import TSNE\n",
    "#from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check for GPU\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# .npy files extracted from file: /global/project/projectdirs/m2676/data/lngs/pgt/raw/geds/LPGTA_r0030_20200718T161311Z_phys_geds_raw.lh5\n",
    "# have to process raw file using raw_to_dsp.py from pygama first, then save waveforms and other parameters into npy file\n",
    "\n",
    "#load data and print dimensions of data set\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "waveforms = np.load('g032_waveforms_phys.npy')\n",
    "psd_sum10 = np.load('g032_psd_sum10_phys.npy')\n",
    "bl_slope  = np.load('g032_bl_slope_phys.npy')\n",
    "\n",
    "train_data = waveforms[0:7650,:]\n",
    "test_data = waveforms[7650:9600,:] #lose 6 observations for validation\n",
    "test_psd10 = psd_sum10[7650:9600]\n",
    "test_bl_slope = bl_slope[7650:9600]\n",
    "\n",
    "print(waveforms.shape)\n",
    "print(train_data.shape)\n",
    "print(test_data.shape)\n",
    "print(test_psd10.shape)\n",
    "print(test_bl_slope.shape)\n",
    "\n",
    "plt.plot(np.arange(len(waveforms[44,:])), waveforms[44,:]) #anomalous sample wf \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocess and convert data to tensors\n",
    "\n",
    "#scaler = StandardScaler()\n",
    "#scaled_data = scaler.fit_transform(train_data,y=None) #scales train data \n",
    "#print(scaled_data.shape)\n",
    "\n",
    "train_data, test_data = map(torch.tensor, (train_data, test_data))\n",
    "\n",
    "# batch size \n",
    "bs = 50 \n",
    "\n",
    "#train data loader\n",
    "train_ds = TensorDataset(train_data)\n",
    "train_dl = DataLoader(train_ds, batch_size=bs) #removed batch shuffling here\n",
    "\n",
    "#test data loader\n",
    "valid_ds = TensorDataset(test_data)\n",
    "valid_dl = DataLoader(valid_ds, batch_size=bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Send data to GPU\n",
    "def preprocess(x):\n",
    "    return x.to(DEVICE)\n",
    "\n",
    "class WrappedDataLoader:\n",
    "    def __init__(self, dl, func):\n",
    "        self.dl = dl\n",
    "        self.func = func\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dl)\n",
    "\n",
    "    def __iter__(self):\n",
    "        batches = iter(self.dl)\n",
    "        for b in batches:\n",
    "            yield (self.func(*b))\n",
    "            \n",
    "train_dl = WrappedDataLoader(train_dl, preprocess)\n",
    "valid_dl = WrappedDataLoader(valid_dl,preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define Convolutional Autoencoder\n",
    "\n",
    "class waveform_cae_aobo(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(waveform_cae_aobo, self).__init__()\n",
    "        \n",
    "        self.lrelu = nn.LeakyReLU(0)\n",
    "        \n",
    "        #Encoder\n",
    "        self.conv1 = nn.Conv1d(1, 10, kernel_size=20, stride=1)\n",
    "        self.conv2 = nn.Conv1d(10, 10, kernel_size=20, stride=1)\n",
    "        self.conv3 = nn.Conv1d(10, 10, kernel_size=20, stride=1)\n",
    "        self.batchnorm1 = nn.BatchNorm1d(10)\n",
    "        self.maxpool = nn.MaxPool1d(5)\n",
    "        self.fc1 = nn.Linear(6390, 980)\n",
    "        self.fc2 = nn.Linear(980, 100)\n",
    "        self.do1 = nn.Dropout(p=0.5)\n",
    "        self.do2 = nn.Dropout(p=0.5)\n",
    "        \n",
    "        #Decoder\n",
    "        self.deconv1 = nn.ConvTranspose1d(10,10,kernel_size=20,stride=1)\n",
    "        self.deconv2 = nn.ConvTranspose1d(10,10,kernel_size=20,stride=1)\n",
    "        self.deconv3 = nn.ConvTranspose1d(10,1,kernel_size=20,stride=1)\n",
    "        self.batchnorm2 = nn.BatchNorm1d(10)\n",
    "        self.fc3 = nn.Linear(100,980)\n",
    "        self.fc4 = nn.Linear(980,6390)\n",
    "        self.upsample = nn.Upsample(3404)\n",
    "        self.do3 = nn.Dropout(p=0.5)\n",
    "        self.do4 = nn.Dropout(p=0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        #Encoding part \n",
    "        x = x.view(bs,1,3404)\n",
    "        x = self.lrelu(self.conv1(x))\n",
    "        x = self.maxpool(x)\n",
    "        x = self.batchnorm1(x)\n",
    "        x = self.lrelu(self.conv2(x))\n",
    "        x = self.lrelu(self.conv3(x))\n",
    "        x = self.do1(x)\n",
    "        x = torch.flatten(x,1)\n",
    "        x = self.lrelu(self.fc1(x))\n",
    "        x = self.do2(x)\n",
    "        x = self.lrelu(self.fc2(x))\n",
    "        fvec = x\n",
    "        \n",
    "        #Decoding part \n",
    "        x = self.lrelu(self.fc3(x))\n",
    "        x = self.do3(x)\n",
    "        x = self.lrelu(self.fc4(x))\n",
    "        x = self.do4(x)\n",
    "        x = x.view(bs,10,639)\n",
    "        x = self.lrelu(self.deconv1(x))\n",
    "        x = self.lrelu(self.deconv2(x))\n",
    "        x = self.batchnorm2(x)\n",
    "        x = self.lrelu(self.deconv3(x))\n",
    "        x = self.upsample(x)\n",
    "        x = torch.flatten(x,1)\n",
    "        return x, fvec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Summarize model, make sure dimensions match in between layers\n",
    "\n",
    "model = waveform_cae_aobo()\n",
    "print(summary(model,torch.zeros(bs,3404),show_hierarchical=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training function \n",
    "def train(model, num_epochs, batch_size, learning_rate, filename):\n",
    "    torch.manual_seed(42)\n",
    "    criterion = nn.MSELoss()# mean squared error loss\n",
    "    criterion.to(DEVICE)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-5) # <--\n",
    "\n",
    "    epochs = []\n",
    "    losses = []\n",
    "    wfs = []\n",
    "    recons = []\n",
    "    \n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        for data in train_dl:\n",
    "            wf = data\n",
    "            recon, _ = model(wf)\n",
    "            loss = criterion(recon, wf)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "\n",
    "            \n",
    "            if epoch == (num_epochs-1):     #save waveforms for last epoch only \n",
    "                wfs.append(wf.cpu().detach())\n",
    "                recons.append(recon.cpu().detach())\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "        epochs.append(epoch)\n",
    "        losses.append(loss)\n",
    "        print('Epoch:{}, Loss:{:.4f}'.format(epoch+1, float(loss)))\n",
    "        \n",
    "    torch.save(model.state_dict(), filename)\n",
    "        \n",
    "    return epochs, losses, wfs, recons\n",
    "\n",
    "#validating function \n",
    "def validate(model, num_epochs):\n",
    "    torch.manual_seed(42)\n",
    "    criterion = nn.MSELoss()# mean squared error loss\n",
    "    criterion.to(DEVICE)\n",
    "    \n",
    "    fvecs = []\n",
    "    model.eval()\n",
    "    for epoch in range(num_epochs):\n",
    "        with torch.no_grad():\n",
    "            for data in valid_dl:\n",
    "                wf = data\n",
    "                recon, fvec = model(wf)\n",
    "                loss = criterion(recon, wf)\n",
    "                if epoch == (num_epochs-1):     #save fvecs for last epoch only \n",
    "                    fvecs.append(fvec.cpu())\n",
    "                else:\n",
    "                    continue\n",
    "                \n",
    "        print('Epoch:{}, Loss:{:.4f}'.format(epoch+1, float(loss)))\n",
    "              \n",
    "    return fvecs\n",
    "\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train model \n",
    "import time\n",
    "\n",
    "max_epochs = 30\n",
    "lr = 1e-4\n",
    "\n",
    "model.to(DEVICE)\n",
    "start_time = time.time()\n",
    "epochs, losses, wfs, recons = train(model, max_epochs, bs, lr,'mse_lr0001_lrelu0_30epochs.pt')\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#concatenate training model outputs\n",
    "train_wfs = np.concatenate(wfs, axis=0)\n",
    "train_recons = np.concatenate(recons, axis=0)\n",
    "print(train_wfs.shape)\n",
    "print(train_recons.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot input and corresponding reconstructed waveform\n",
    "\n",
    "#plt.suptitle(\"Sample input and reconstructed waveform\", fontsize=18)\n",
    "plt.plot(np.arange(len(train_wfs[8,:])), train_wfs[8,:], label='input')\n",
    "plt.plot(np.arange(len(train_recons[8,:])), train_recons[8,:], label='reconstructed')\n",
    "plt.ylabel('ADC', fontsize=20)\n",
    "plt.xlabel(\"ns\", fontsize=20)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(np.arange(len(train_wfs[86,:])), train_wfs[86,:], label='input')\n",
    "plt.plot(np.arange(len(train_recons[86,:])), train_recons[86,:], label='reconstructed')\n",
    "plt.ylabel('ADC', fontsize=20)\n",
    "plt.xlabel(\"ns\", fontsize=20)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(np.arange(len(train_wfs[2840,:])), train_wfs[2840,:], label='input')\n",
    "plt.plot(np.arange(len(train_recons[2840,:])), train_recons[2840,:], label='reconstructed')\n",
    "plt.ylabel('ADC', fontsize=20)\n",
    "plt.xlabel(\"ns\", fontsize=20)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(np.arange(len(train_wfs[4811,:])), train_wfs[4811,:], label='input')\n",
    "plt.plot(np.arange(len(train_recons[4811,:])), train_recons[4811,:], label='reconstructed')\n",
    "plt.ylabel('ADC', fontsize=20)\n",
    "plt.xlabel(\"ns\", fontsize=20)\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot loss function of CAE\n",
    "epochs = np.asarray(epochs)\n",
    "losses = np.asarray(losses)\n",
    "plt.plot(epochs,losses)\n",
    "plt.title('Reconstruction Learning Curve (Background)', fontsize=16)\n",
    "plt.ylabel('Loss Criterion (MSE)', fontsize=14)\n",
    "plt.xlabel(\"Epoch\", fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test model, obtain feature vectors to feed into TSNE\n",
    "#import time\n",
    "#model.load_state_dict(torch.load('mse_lr0001_lrelu01_30epochs.pt'))\n",
    "#model.to(DEVICE)\n",
    "\n",
    "max_epochs = 20\n",
    "start_time = time.time()\n",
    "fvecs = validate(model,max_epochs)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#concatenate results from validation step\n",
    "test_fvecs = np.concatenate(fvecs ,axis=0)\n",
    "np.shape(test_fvecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feed fvecs into TSNE\n",
    "\n",
    "start_time = time.time()\n",
    "test_embedded = TSNE(verbose=0, n_components=2, learning_rate=200).fit_transform(test_fvecs)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "print(test_embedded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "from matplotlib.lines import Line2D\n",
    "matplotlib.use('Agg')\n",
    "\n",
    "#Define t-SNE plotting functions\n",
    "def plot_all_clusters(embedded_fvecs, filename):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.plot(embedded_fvecs[:, 0], embedded_fvecs[:, 1], 'b.', markersize=1)\n",
    "    fig.suptitle(\"t-SNE Classification of Waveforms\", fontsize=18)\n",
    "    fig.savefig(filename)\n",
    "    \n",
    "def plot_all_clusters_psd(embedded_fvecs, tags, filename):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    for i in range(0,len(tags)):\n",
    "        if tags[i] >= 0.65e6: #high freq. threshold here\n",
    "            ax.plot(embedded_fvecs[i, 0], embedded_fvecs[i, 1], 'r.', markersize=10)\n",
    "        else:\n",
    "            ax.plot(embedded_fvecs[i, 0], embedded_fvecs[i, 1], 'b.', markersize=1)\n",
    "            \n",
    "    fig.suptitle(\"t-SNE with PSD Tags\", fontsize=18)\n",
    "    legend_elements = [Line2D([0], [0], marker='.', color='w', label='low psd_sum10', markerfacecolor='b', markersize=15),\n",
    "                       Line2D([0], [0], marker='.', color='w', label='high psd_sum10', markerfacecolor='r', markersize=15)]\n",
    "    ax.legend(handles=legend_elements, fancybox=True, loc='upper right')\n",
    "    fig.savefig(filename)\n",
    "    \n",
    "\n",
    "def plot_all_clusters_bl_slope(embedded_fvecs, tags, filename):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    for i in range(0,len(tags)):\n",
    "        if tags[i] >= 0.1:  #outlier cuts here \n",
    "            ax.plot(embedded_fvecs[i, 0], embedded_fvecs[i, 1], 'r.', markersize=10)\n",
    "        elif tags[i] < -0.1:\n",
    "            ax.plot(embedded_fvecs[i, 0], embedded_fvecs[i, 1], 'r.', markersize=10)\n",
    "        else:\n",
    "            ax.plot(embedded_fvecs[i, 0], embedded_fvecs[i, 1], 'b.', markersize=1)\n",
    "            \n",
    "    fig.suptitle(\"t-SNE with Baseline Slope Tags\", fontsize=18)\n",
    "    legend_elements = [Line2D([0], [0], marker='.', color='w', label='central bl_slope', markerfacecolor='b', markersize=15),\n",
    "                       Line2D([0], [0], marker='.', color='w', label='outlier bl_slope', markerfacecolor='r', markersize=15)]\n",
    "    ax.legend(handles=legend_elements, fancybox=True, loc='upper right')\n",
    "    fig.savefig(filename)\n",
    "    \n",
    "def plot_2Dhist(embedded_fvecs, filename):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    h = ax.hist2d(embedded_fvecs[:, 0], embedded_fvecs[:, 1], bins=50, density=True, cmap='hot')\n",
    "    fig.colorbar(h[3], ax=ax)\n",
    "    fig.suptitle(\"Density Plot of t-SNE Results\", fontsize=18)\n",
    "    fig.savefig(filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot TSNE performance for various digits \n",
    "\n",
    "plot_all_clusters(test_embedded, \"tsne_mse_lr0001_lrelu0\")\n",
    "plot_2Dhist(test_embedded, \"2Dhist_mse_lr0001_lrelu0\")\n",
    "plot_all_clusters_psd(test_embedded, test_psd10, \"tsne_mse_lr0001_lrelu0_psd\")\n",
    "plot_all_clusters_bl_slope(test_embedded, test_bl_slope, \"tsne_mse_lr0001_lrelu0_bl_slope\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_gpu_kernel",
   "language": "python",
   "name": "pytorch_gpu_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
