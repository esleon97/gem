{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This code uses the multi head self attention (Transformer) model to perform Network PSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import argparse\n",
    "import time\n",
    "import math\n",
    "import random\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch.nn import init\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import torch.utils.data as data_utils\n",
    "from torch.utils.data import Dataset, DataLoader, SubsetRandomSampler\n",
    "import gzip\n",
    "import pickle5 as pickle\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "from scipy import sparse\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import torchsnooper\n",
    "\n",
    "from torch import nn, einsum\n",
    "from einops import rearrange, repeat\n",
    "from einops.layers.torch import Rearrange\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "These 2 parameters define the range of waveform we'd like to analyze\n",
    "'''\n",
    "LSPAN = 300 # number of time samples prior to t0\n",
    "HSPAN = 300 # number of time samples after t0\n",
    "DATA_EMB_DIM = 500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "gets the false positive rate, true positive rate, cutting threshold and area under curve using the given signal and background array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_roc(sig,bkg):\n",
    "    testY = np.array([1]*len(sig) + [0]*len(bkg))\n",
    "    predY = np.array(sig+bkg)\n",
    "    auc = roc_auc_score(testY, predY)\n",
    "    fpr, tpr, thr = roc_curve(testY, predY)\n",
    "    return fpr,tpr,thr,auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DetectorDataset(Dataset):\n",
    "\n",
    "    def __init__(self, dep=\"DEP_P42575A_10percent.pickle\", sep = \"SEP_P42575A_10percent.pickle\",dsize=-1):\n",
    "        \n",
    "        DEP_dict = self.event_loader(dep)\n",
    "        SEP_dict = self.event_loader(sep)\n",
    "\n",
    "        if dsize == -1:\n",
    "            dsize = min(len(DEP_dict), len(SEP_dict))\n",
    "        \n",
    "        #Shuffle dataset and select #dsize event from DEP and SEP\n",
    "        np.random.shuffle(DEP_dict)\n",
    "        np.random.shuffle(SEP_dict)\n",
    "        DEP_dict = DEP_dict[:dsize]\n",
    "        SEP_dict = SEP_dict[:dsize]\n",
    "        self.event_dict = DEP_dict + SEP_dict\n",
    "        self.label = ([1]*len(DEP_dict)) + ([0] * len(SEP_dict))\n",
    "        \n",
    "        self.size = len(self.event_dict)\n",
    "        print(self.size)\n",
    "        \n",
    "        #Get offset values:\n",
    "        self.max_offset = np.max(self.get_field_from_dict(DEP_dict,\"tstart\") + self.get_field_from_dict(SEP_dict,\"tstart\"))\n",
    "        \n",
    "        #Get all unique detector name:\n",
    "        self.detector_name = np.unique(self.get_field_from_dict(DEP_dict,\"detector\") + self.get_field_from_dict(SEP_dict,\"detector\"))\n",
    "        \n",
    "        self.data_emb_dim = DATA_EMB_DIM\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.size\n",
    "    \n",
    "    def build_scaler(self):\n",
    "        '''\n",
    "        '''\n",
    "        wf_array = []\n",
    "        for i in range(self.size):\n",
    "            wf_array.append(self.get_wf(i).reshape(1,-1))\n",
    "        wf_array = np.concatenate(wf_array,axis=0)\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(wf_array)\n",
    "        return scaler\n",
    "    \n",
    "    def get_scaler(self):\n",
    "        return self.scaler\n",
    "    \n",
    "    def set_scaler(self,scaler):\n",
    "        self.scaler = scaler\n",
    "    \n",
    "    def get_wf(self,idx):\n",
    "        event = self.event_dict[idx]\n",
    "        wf = np.array(event[\"wf\"]).flatten()\n",
    "        midindex = event[\"t0\"]\n",
    "\n",
    "        #baseline subtraction\n",
    "        wf -= np.average(wf[:(midindex-50)])\n",
    "        \n",
    "        #Extract waveform from its t0\n",
    "        wfbegin = midindex - LSPAN\n",
    "        wfend = midindex + HSPAN\n",
    "        \n",
    "        wf = wf[wfbegin:wfend]\n",
    "        wf = (wf - np.min(wf)) / (np.max(wf) - np.min(wf))#rescale wf to between 0 and 1\n",
    "\n",
    "        \n",
    "        return wf\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        event = self.event_dict[idx]\n",
    "        wf = np.array(event[\"wf\"]).flatten()\n",
    "        midindex = event[\"t0\"]\n",
    "\n",
    "        wf = self.get_wf(idx)\n",
    "        \n",
    "        avse = event[\"avse\"]\n",
    "        tdrift = event[\"tDrift\"]\n",
    "        \n",
    "        return self.tokenizer(wf), self.label[idx], avse\n",
    "        \n",
    "    def return_label(self):\n",
    "        return self.trainY\n",
    "\n",
    "    def return_detector_array(self):\n",
    "        return self.detector_name\n",
    "    \n",
    "    #Load event from .pickle file\n",
    "    def event_loader(self, address):\n",
    "        wf_list = []\n",
    "        with (open(address, \"rb\")) as openfile:\n",
    "            while True:\n",
    "#                 if len(wf_list) > 2000:\n",
    "#                     break\n",
    "                try:\n",
    "                   wf_list.append(pickle.load(openfile, encoding='latin1'))\n",
    "                except EOFError:\n",
    "                    break\n",
    "        return wf_list\n",
    "    \n",
    "    def get_field_from_dict(self, input_dict, fieldname):\n",
    "        field_list = []\n",
    "        for event in input_dict:\n",
    "            field_list.append(event[fieldname])\n",
    "        return field_list\n",
    "    \n",
    "    def tokenizer(self,x):\n",
    "        '''\n",
    "        Tokenize the waveform\n",
    "        Originally the waveform is a 1D array of floatpoint numbers, say its shape is wf.shape = (1000,)\n",
    "        After tokenizing, its shape becomes wf.shape = (1000,self.data_emb_dim)\n",
    "        Where now in each dimension it is an one-hot vector with length of self.data_emb_dim\n",
    "        Example:\n",
    "            suppose self.data_emb_dim = 10\n",
    "            Then originally we have wf[5] = 0.25\n",
    "            Then after tokenizing, wf[5] becomes [0 0 1 0 0 0 0 0 0 0]\n",
    "        '''\n",
    "        nbins = self.data_emb_dim\n",
    "        x += np.random.rand(len(x)) * 0.02 - 0.01\n",
    "        x = np.clip(x,0.0,1.0)\n",
    "        token_range = np.linspace(0.0,1.0,nbins+1)\n",
    "        return np.array([np.argwhere(xval>=token_range)[-1,0] for xval in x])\n",
    "    \n",
    "    def get_data_emb(self):\n",
    "        return self.data_emb_dim\n",
    "        \n",
    "# print(next(iter(DetectorDataset())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modules of the multi-head self attention network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PreNorm(nn.Module):\n",
    "    def __init__(self, dim, fn):\n",
    "        super().__init__()\n",
    "        self.norm = nn.LayerNorm(dim)\n",
    "        self.fn = fn\n",
    "    def forward(self, x, **kwargs):\n",
    "        return self.fn(self.norm(x), **kwargs)\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, dim, hidden_dim, dropout = 0.):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(dim, hidden_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim, dim),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, dim, heads = 8, dim_head = 64, dropout = 0.):\n",
    "        super().__init__()\n",
    "        '''\n",
    "        The multi-head self attention moduel\n",
    "        q: query\n",
    "        k: key\n",
    "        v: value\n",
    "        q,k,v are produced by multiplying kernel matrices to the input at each time\n",
    "        '''\n",
    "        inner_dim = dim_head *  heads\n",
    "        project_out = not (heads == 1 and dim_head == dim)\n",
    "\n",
    "        self.heads = heads\n",
    "        self.scale = dim_head ** -0.5\n",
    "\n",
    "        self.attend = nn.Softmax(dim = -1)\n",
    "        self.to_qkv = nn.Linear(dim, inner_dim * 3, bias = False)\n",
    "\n",
    "        self.to_out = nn.Sequential(\n",
    "            nn.Linear(inner_dim, dim),\n",
    "            nn.Dropout(dropout)\n",
    "        ) if project_out else nn.Identity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, n, _, h = *x.shape, self.heads\n",
    "        qkv = self.to_qkv(x).chunk(3, dim = -1)\n",
    "        q, k, v = map(lambda t: rearrange(t, 'b n (h d) -> b h n d', h = h), qkv)\n",
    "\n",
    "        dots = einsum('b h i d, b h j d -> b h i j', q, k) * self.scale\n",
    "\n",
    "        attn = self.attend(dots)\n",
    "\n",
    "        out = einsum('b h i j, b h j d -> b h i d', attn, v)\n",
    "        out = rearrange(out, 'b h n d -> b n (h d)')\n",
    "        return self.to_out(out)\n",
    "\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self, dim, depth, heads, dim_head, mlp_dim, dropout = 0.):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList([])\n",
    "        for _ in range(depth):\n",
    "            self.layers.append(nn.ModuleList([\n",
    "                PreNorm(dim, Attention(dim, heads = heads, dim_head = dim_head, dropout = dropout)),\n",
    "                PreNorm(dim, FeedForward(dim, mlp_dim, dropout = dropout))\n",
    "            ]))\n",
    "    def forward(self, x):\n",
    "        for attn, ff in self.layers:\n",
    "            x = attn(x) + x\n",
    "            x = ff(x) + x\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load dataset\n",
    "def load_data(batch_size):\n",
    "\n",
    "    dataset = DetectorDataset()\n",
    "    test_dataset = DetectorDataset(dep=\"DEP_P42575A_Co56.pickle\")\n",
    "    validation_split = .3 #Split data set into training & testing with 7:3 ratio\n",
    "    shuffle_dataset = True\n",
    "    random_seed= 42222\n",
    "\n",
    "    #make sure we have the same amount of signal/bkg in the training/test dataset\n",
    "    division = 2\n",
    "    dataset_size = int(len(dataset)/division)\n",
    "    indices = list(range(dataset_size))\n",
    "    split = int(np.floor(validation_split * dataset_size))\n",
    "    if shuffle_dataset :\n",
    "        np.random.seed(random_seed)\n",
    "        np.random.shuffle(indices)\n",
    "    train_indices, val_indices = indices[split:], indices[:split]\n",
    "\n",
    "    train_indices += list(division*dataset_size - 1-np.array(train_indices))\n",
    "    val_indices += list(division*dataset_size- 1-np.array(val_indices))\n",
    "\n",
    "    np.random.shuffle(train_indices)\n",
    "    np.random.shuffle(val_indices)\n",
    "    \n",
    "    test_dataset_size = int(len(test_dataset))\n",
    "    test_indices = list(range(test_dataset_size))\n",
    "    if shuffle_dataset :\n",
    "        np.random.seed(random_seed)\n",
    "        np.random.shuffle(test_indices)\n",
    "\n",
    "    train_sampler = SubsetRandomSampler(train_indices)\n",
    "    valid_sampler = SubsetRandomSampler(test_indices)\n",
    "\n",
    "    train_loader = data_utils.DataLoader(dataset, batch_size=batch_size, sampler=train_sampler, drop_last=True)\n",
    "    test_loader = data_utils.DataLoader(test_dataset, batch_size=batch_size,sampler=valid_sampler,  drop_last=True)\n",
    "\n",
    "    return train_loader,test_loader, dataset.get_data_emb()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Transformer Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WaveTransformer(nn.Module):\n",
    "    def __init__(self,data_emb, get_attention = False):\n",
    "        super(WaveTransformer, self).__init__()\n",
    "        self.seg = 1      #Segment waveform to reduce its length. If the original waveform is (2000,1), then segment it with self.seg=5 can reduce its length to (400,5)\n",
    "        self.embedding_dim = 64  # Embedding dimension\n",
    "        self.seq_len = (HSPAN + LSPAN)//self.seg\n",
    "        self.embedding = nn.Embedding(data_emb, self.embedding_dim)\n",
    "        # This is the classification token, it attends different parts of the wavefom to make classification decision\n",
    "        self.cls_token = nn.Parameter(torch.randn(1, 1, self.embedding_dim))\n",
    "        # dim, depth, heads, dim_head, mlp_dim, dropout = 0.\n",
    "        self.transformer = Transformer(self.embedding_dim,1,10,32, 1024,0.3)\n",
    "        # Positional encoder, learning during training. It's length is seq_len + 1 because we need to hold the classification token at the beginning\n",
    "        self.pos_encoder = nn.Parameter(torch.randn(1, self.seq_len+1, self.embedding_dim))\n",
    "        self.mlp_head = nn.Sequential(\n",
    "            nn.LayerNorm(self.embedding_dim),\n",
    "            nn.Linear(self.embedding_dim, 1)\n",
    "        )\n",
    "\n",
    "#     @torchsnooper.snoop()\n",
    "    def forward(self, x):\n",
    "        b,n = x.size()\n",
    "        x = self.embedding(x)  # [batch, seq_len, data_embedding_dimension] -> [batch, seq_len, self.embedding_dim]\n",
    "        cls_tokens = repeat(self.cls_token, '() n d -> b n d', b = b) # [1, 1, self.embedding_dim] -> [batch, 1, self.embedding_dim]\n",
    "        x = torch.cat((cls_tokens, x), dim=1) # {[batch, seq_len, self.embedding_dim], [batch, 1, self.embedding_dim]} -> [batch, seq_len+1, self.embedding_dim]\n",
    "        x += self.pos_encoder[:, :(n + 1)]\n",
    "        \n",
    "        x = self.transformer(x)[:,0] # Feed through the transformer model, then select only the 0th element in the sequence (that is, the classification token)\n",
    "        return self.mlp_head(x)      # Feed cls_token to a fully connected NN for classification decision\n",
    "\n",
    "    def get_emb_dim(self):\n",
    "        return self.embedding_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11576\n",
      "4868\n"
     ]
    }
   ],
   "source": [
    "#Load data\n",
    "BATCH_SIZE = 4\n",
    "train_loader, test_loader, data_emb_dim = load_data(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This feeds the waveform into classifier and get sigmoid output for signal and background events\n",
    "def get_sigmoid(waveform_in, labels_in ,classifier_in):\n",
    "    waveform_in = waveform_in.to(DEVICE).long()\n",
    "    labels_in = labels_in.to(DEVICE).float()\n",
    "    outputs_in  = classifier_in(waveform_in)\n",
    "\n",
    "    lb_data_in = labels_in.cpu().data.numpy().flatten()\n",
    "    outpt_data_in = outputs_in.cpu().data.numpy().flatten()\n",
    "\n",
    "    signal_in = np.argwhere(lb_data_in == 1.0)\n",
    "    bkg_in = np.argwhere(lb_data_in == 0.0)\n",
    "\n",
    "    return list(outpt_data_in[signal_in].flatten()), list(outpt_data_in[bkg_in].flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the transformer classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#params 259521\n",
      "Warmup Size: 4000\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: an illegal memory access was encountered",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-c52cc9c75b1c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mwaveform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mavse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mRNNclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mwaveform\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaveform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: an illegal memory access was encountered"
     ]
    }
   ],
   "source": [
    "NUM_EPOCHS = 50\n",
    "\n",
    "#Define RNN network\n",
    "RNNclassifier = WaveTransformer(data_emb_dim)\n",
    "LEARNING_RATE =RNNclassifier.get_emb_dim()**-0.5\n",
    "RNNclassifier.to(DEVICE)\n",
    "\n",
    "\n",
    "\n",
    "print(\"#params\", sum(x.numel() for x in RNNclassifier.parameters()))\n",
    "\n",
    "RNNcriterion = torch.nn.BCEWithLogitsLoss() #BCEWithLogitsLoss does not require the last layer to be sigmoid\n",
    "RNNcriterion = RNNcriterion.to(DEVICE)\n",
    "\n",
    "# Warmup training scheme\n",
    "# This allows the attention mechanism to learn general features of data in first few epochs\n",
    "warmup_size = 4000 # Warm up step used in transformer paper\n",
    "print(\"Warmup Size: %d\"%(warmup_size))\n",
    "lmbda = lambda epoch: min((epoch+1)**-0.5, (epoch+1)*warmup_size**-1.5)\n",
    "RNNoptimizer = torch.optim.AdamW(RNNclassifier.parameters(),lr=LEARNING_RATE, betas=(0.9, 0.98),eps=1e-9)\n",
    "scheduler = torch.optim.lr_scheduler.LambdaLR(RNNoptimizer, lr_lambda=lmbda)\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    for i, (waveform, labels, avse) in enumerate(train_loader):\n",
    "        RNNclassifier.train()\n",
    "        waveform = waveform.to(DEVICE).long()\n",
    "        labels = labels.to(DEVICE).float()\n",
    "        labels = labels.view(-1,1)\n",
    "        \n",
    "        #Train RNN\n",
    "        RNNoutputs  = RNNclassifier(waveform)\n",
    "        RNNloss = RNNcriterion(RNNoutputs, labels)\n",
    "        \n",
    "        RNNloss.backward()\n",
    "        RNNoptimizer.step()        # update parameters of net\n",
    "        RNNoptimizer.zero_grad()   # reset gradient\n",
    "        scheduler.step()\n",
    "\n",
    "    print('\\rEpoch [{0}/{1}], Iter [{2}/{3}] Loss: {4:.4f}'.format(\n",
    "        epoch+1, NUM_EPOCHS, i+1, len(train_loader),\n",
    "        RNNloss.item(), end=\"\"),end=\"\")\n",
    "    sigmoid_s_RNN = []\n",
    "    sigmoid_b_RNN = []\n",
    "    avse_s = []\n",
    "    avse_b = []\n",
    "\n",
    "    for waveform,labels,avse in tqdm(test_loader):\n",
    "\n",
    "        RNNclassifier.eval()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            sig_RNN, bkg_RNN = get_sigmoid(waveform, labels, RNNclassifier)\n",
    "\n",
    "            lb_data = labels.cpu().data.numpy().flatten()\n",
    "            avse_data = avse.cpu().data.numpy().flatten()\n",
    "            \n",
    "            signal = np.argwhere(lb_data == 1.0)\n",
    "            bkg = np.argwhere(lb_data == 0.0)\n",
    "            \n",
    "            sigmoid_s_RNN += sig_RNN\n",
    "            sigmoid_b_RNN += bkg_RNN\n",
    "            \n",
    "            avse_s += list(avse_data[signal].flatten())\n",
    "            avse_b += list(avse_data[bkg].flatten())\n",
    "\n",
    "    #Set the range of scatter plot from 5% to 95% quantile of sigmoid output\n",
    "    xlow = np.quantile(sigmoid_s_RNN+sigmoid_b_RNN,0.05)\n",
    "    xhi = np.quantile(sigmoid_s_RNN+sigmoid_b_RNN,0.95)\n",
    "\n",
    "    # Plot the ROC curve for RNN and AvsE\n",
    "    fpr_rnn, tpr_rnn, thr_rnn, auc_rnn = get_roc(sigmoid_s_RNN, sigmoid_b_RNN)\n",
    "    fpr_avse, tpr_avse, thr_avse, auc_avse = get_roc(avse_s, avse_b)\n",
    "    rej_tpr = tpr_avse[np.argmin(np.abs(thr_avse+1.0))]\n",
    "    plt.plot(fpr_rnn,tpr_rnn,label=\"Transformer AUC: %.3f SEP Remain: %.1f%%\"%(auc_rnn,fpr_rnn[np.argmin(np.abs(tpr_rnn-rej_tpr))]*100.0))\n",
    "    plt.plot(fpr_avse,tpr_avse,label=\"AvsE AUC: %.3f SEP Remain: %.1f%%\"%(auc_avse,fpr_avse[np.argmin(np.abs(thr_avse+1.0))]*100.0))\n",
    "    plt.legend()\n",
    "    plt.savefig(\"ROC.png\",dpi=200)\n",
    "    plt.show()\n",
    "    plt.cla()\n",
    "    plt.clf()\n",
    "    plt.close()\n",
    "    \n",
    "    #Save CNN and RNN models.\n",
    "    torch.save(RNNclassifier.state_dict(), 'RNN.pt')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion plot of A vs. E and RNN classifier\n",
    "xlow = np.quantile(sigmoid_s_RNN+sigmoid_b_RNN,0)\n",
    "xhi = np.quantile(sigmoid_s_RNN+sigmoid_b_RNN,1.00)\n",
    "ylow = -10\n",
    "yhi =2\n",
    "\n",
    "threshold_rnn = thr_rnn[np.argmin(np.abs(tpr_rnn-tpr_avse[np.argmin(np.abs(thr_avse+1.0))]))]\n",
    "\n",
    "#Plot sigmoid output for DEP events\n",
    "plt.hist2d(sigmoid_s_RNN, avse_s,bins = (np.linspace(xlow,xhi,100),np.linspace(ylow,yhi,100)),cmap=\"PuRd\",norm=matplotlib.colors.LogNorm())\n",
    "plt.axhline(y=-1,color=\"blue\")\n",
    "plt.axvline(x=threshold_rnn,color=\"blue\")\n",
    "plt.title(\"Network Output of DEP\")\n",
    "plt.xlabel(\"RNN Output\")\n",
    "plt.ylabel(\"AvsE Corrected\")\n",
    "# plt.legend()\n",
    "plt.savefig(\"AR_signal.png\",dpi=200)\n",
    "plt.show()\n",
    "plt.cla()\n",
    "plt.clf()\n",
    "plt.close()\n",
    "\n",
    "#Plot sigmoid output for SEP events\n",
    "plt.hist2d(sigmoid_b_RNN, avse_b,bins = (np.linspace(xlow,xhi,100),np.linspace(ylow,yhi,100)),cmap=\"PuRd\",norm=matplotlib.colors.LogNorm())\n",
    "plt.axhline(y=-1,color=\"blue\")\n",
    "plt.axvline(x=threshold_rnn,color=\"blue\")\n",
    "plt.title(\"Network Output of SEP\")\n",
    "plt.xlabel(\"RNN Output\")\n",
    "plt.ylabel(\"AvsE Corrected\")\n",
    "# plt.legend()\n",
    "plt.savefig(\"AR_bkg.png\",dpi=200)\n",
    "plt.show()\n",
    "plt.cla()\n",
    "plt.clf()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Network output for DEP events\n",
    "plt.hist(sigmoid_s_RNN, bins = np.linspace(xlow,xhi,100),color=\"red\",histtype=\"step\",label=\"DEP\")\n",
    "plt.hist(sigmoid_b_RNN, bins = np.linspace(xlow,xhi,100),color=\"blue\",histtype=\"step\",label=\"SEP\")\n",
    "plt.title(\"RNN output\")\n",
    "plt.xlabel(\"RNN Sigmoid Output\")\n",
    "plt.ylabel(\"RNN output\")\n",
    "plt.legend()\n",
    "plt.savefig(\"RNN1d.png\",dpi=200)\n",
    "plt.show()\n",
    "plt.cla()\n",
    "plt.clf()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_attention(waveform, attscore,bkg=False):\n",
    "    '''\n",
    "    This function plots the attention score distribution on given waveform\n",
    "    waveform: the vector of original waveform\n",
    "    attscore: the attention score obtained from the RNN\n",
    "    '''\n",
    "    from matplotlib import cm\n",
    "    from matplotlib import gridspec\n",
    "    colormap_normal = cm.get_cmap(\"cool\")\n",
    "    \n",
    "    waveform=np.array(waveform)\n",
    "    attscore = np.array(attscore)\n",
    "    fig = plt.figure(figsize=(20, 12))\n",
    "    gs = gridspec.GridSpec(1, 2, width_ratios=[8,1]) \n",
    "\n",
    "    plt.subplot(gs[0])\n",
    "    rescale = lambda y: (y - np.min(y)) / (np.max(y) - np.min(y))\n",
    "    len_wf = len(waveform)\n",
    "    print(np.linspace(0,len_wf,len_wf).shape,waveform.shape, rescale(attscore).shape)\n",
    "    plt.bar(np.linspace(0,len_wf,len_wf),waveform,width=1.5, color=colormap_normal(rescale(attscore)))\n",
    "    plt.xlabel(\"Time Sample\")\n",
    "    plt.ylabel(\"ADC Counts\")\n",
    "\n",
    "    loss_ax_scale = fig.add_subplot(gs[1])\n",
    "    loss_ax_scale.set_xticks([])\n",
    "    loss_ax_scale.tick_params(length=0)\n",
    "    plt.yticks([1,72], [\"High Attention\", \"Low Attention\"],rotation=90)  # Set text labels and properties.\n",
    "\n",
    "    # loss_ax_scale.set_yticks([1.0,0.0])\n",
    "    # loss_ax_scale.set_yticklabels([\"High Attention\", \"Low Attention\"],rotation=90)\n",
    "    loss_scale = np.linspace(1.0, 0.0, 100)\n",
    "\n",
    "    for i in range(0,1):\n",
    "        loss_scale = np.vstack((loss_scale,loss_scale))\n",
    "    loss_scale = loss_ax_scale.imshow(np.transpose(loss_scale),cmap=colormap_normal, interpolation='nearest')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    if bkg:\n",
    "        plt.savefig(\"att_nhit_bkg.png\",dpi=200)\n",
    "    else:\n",
    "        plt.savefig(\"att_nhit_sig.png\",dpi=200)\n",
    "    plt.cla()\n",
    "    plt.clf()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "wf = np.array([0]*160+np.linspace(0,1,20).tolist() + np.linspace(1,0.8,120).tolist())+np.random.randn(300)*0.02\n",
    "wf = (wf - np.min(wf)) / (np.max(wf) - np.min(wf))#rescale wf to between 0 and 1\n",
    "\n",
    "#Set the RNN to attention score mode\n",
    "attentionRNN = RNN(True)\n",
    "attentionRNN.to(DEVICE).double()\n",
    "model_dict = attentionRNN.state_dict()\n",
    "pretrained_dict = torch.load('RNN.pt',map_location='cpu')\n",
    "model_dict.update(pretrained_dict) \n",
    "attentionRNN.load_state_dict(pretrained_dict)\n",
    "\n",
    "attentionRNN.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "\n",
    "    waveform = torch.tensor(wf).to(DEVICE).view(1,-1,1).expand(32,300,1).double()\n",
    "    attention  = attentionRNN(waveform)\n",
    "    attention = torch.sum(attention,dim=1)\n",
    "    \n",
    "    ibatch=0\n",
    "    wf = waveform[ibatch]#.view(600,3)[:,0]\n",
    "    attention = attention[ibatch]\n",
    "    plot_attention(wf.cpu().data.numpy().flatten(), attention.cpu().data.numpy().flatten())\n",
    "    assert 0\n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bdt",
   "language": "python",
   "name": "bdt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
